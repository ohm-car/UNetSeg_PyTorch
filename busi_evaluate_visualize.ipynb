{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional.classification import binary_jaccard_index\n",
    "from torchvision.models.segmentation.deeplabv3 import deeplabv3_resnet50\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# from architectures.unet_model_xB import UNet as UNet_ml\n",
    "# from architectures.unet_model_seg import UNet as UNet_seg\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.BUSI_multiloss import BUSIDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f8f743",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04669ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4e685",
   "metadata": {},
   "source": [
    "### Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 0\n",
    "torch.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ff720",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path().resolve().parent\n",
    "print(root_dir)\n",
    "\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(root_dir,\n",
    "                    val_percent=0.1):\n",
    "\n",
    "    global n_train, n_val\n",
    "\n",
    "#     root_dir = root_dir\n",
    "\n",
    "    dataset = BUSIDataset(root_dir, im_res = 224, threshold = 100)\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train, val = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers = 2)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers = 2, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_loader = get_dataloaders(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023433b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6255eae2",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "\n",
    "Load weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model_path = '../testModels/2024/10-08_BUSI/CP_Trial30_Epoch160.pth'\n",
    "# ml_model_path = '../testModels/busi_ml/multiloss/CP_Trial30_Epoch160.pth'\n",
    "# seg_model_path = '../pets_final/supervised_segmentation/CP_epoch60.pth'\n",
    "# model_path = 'checkpoints/pascalVOC/multiloss/04-30/17-25-10/CP_epoch2.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Enter the correct arguments for the UNet\n",
    "# net_ml = UNet_ml(n_channels=3, n_classes=1, bilinear=True)\n",
    "\n",
    "# net_ml.load_state_dict(\n",
    "#             torch.load(ml_model_path, map_location=device)\n",
    "#         )\n",
    "# logging.info(f'Model loaded from {ml_model_path}')\n",
    "# # net_ml.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Enter the correct arguments for the UNet\n",
    "# net_seg = UNet_seg(n_channels=3, n_classes=1, bilinear=True)\n",
    "\n",
    "# net_seg.load_state_dict(\n",
    "#             torch.load(seg_model_path, map_location=device)\n",
    "#         )\n",
    "# logging.info(f'Model loaded from {seg_model_path}')\n",
    "# # net_seg.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc56b0",
   "metadata": {},
   "source": [
    "Load weights for deeplabv3 based arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\n",
    "    # model = fcn_resnet50(aux_loss=True)\n",
    "    model = deeplabv3_resnet50(num_classes = 1, aux_loss=True)\n",
    "    aux = nn.Sequential(nn.Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "                 nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                 nn.ReLU(inplace=True),\n",
    "                 nn.Dropout(p=0.1, inplace=False),\n",
    "                 nn.Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1)),\n",
    "                 nn.Sigmoid())\n",
    "    model.aux_classifier = aux\n",
    "    model.classifier.append(nn.Sigmoid())\n",
    "    model.to(device=device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4971593",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ml = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233aa473",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ml.load_state_dict(torch.load(ml_model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f76a8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d5ae581",
   "metadata": {},
   "source": [
    "### Visualization Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6b560",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201dacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_torchToPIL_img(img):\n",
    "    \n",
    "    img = img.squeeze().cpu().numpy()\n",
    "    img = img.transpose((1,2,0))\n",
    "    return Image.fromarray((img * 255).astype(np.uint8), 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_torchToPIL_mask(mask):\n",
    "    \n",
    "    mask = mask.squeeze().cpu().numpy()\n",
    "    mask = np.clip(mask, 0, 1)\n",
    "    return Image.fromarray((mask * 255).astype(np.uint8), 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ebcd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_torchToPIL_mask(mask):\n",
    "    \n",
    "    mask = mask.squeeze().cpu().detach().numpy()\n",
    "    mask = np.clip(mask, 0, 1)\n",
    "    return Image.fromarray((mask * 255).astype(np.uint8), 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_torchToPIL_mask(mask):\n",
    "    \n",
    "    mask = mask.squeeze().cpu().detach().numpy()\n",
    "    mask = np.clip(np.round(mask), 0, 1)\n",
    "    return Image.fromarray((mask * 255).astype(np.uint8), 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49080504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_display_pic(images):\n",
    "    \n",
    "#     widths, heights = 224, 224\n",
    "#     total_width = sum(widths)\n",
    "#     max_height = max(heights)\n",
    "\n",
    "    widths, heights = 224, 224\n",
    "    total_width = widths*len(images) + 10*(len(images) - 1)\n",
    "    max_height = heights\n",
    "    \n",
    "    white_spacing = Image.new('RGB', (10, 224), color='white')\n",
    "\n",
    "    combined_image = Image.new('RGB', (total_width, max_height))\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        combined_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "        combined_image.paste(white_spacing, (x_offset, 0))\n",
    "        x_offset += 10\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25567125",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(torchToPIL_mask(batch['mask'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3914dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_iou(pred_mask, mask):\n",
    "    \n",
    "    iou = binary_jaccard_index(pred_mask, mask)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iou():\n",
    "    \n",
    "    return batch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pred_expected_iou(perc):\n",
    "    \n",
    "    e_iou = perc / (2 - perc)\n",
    "    \n",
    "    return e_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for batch in val_loader:\n",
    "    net_ml.eval()\n",
    "#     net_seg.eval()\n",
    "    print(\"Batch #\",j)\n",
    "    j += 1\n",
    "#     if j > 1:\n",
    "#         break\n",
    "    batch_iou_ml = 0\n",
    "    batch_iou_seg = 0\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        img = batch['image'][i]\n",
    "        mask = batch['mask'][i]\n",
    "        perc = batch['mask_perc'][i]\n",
    "        \n",
    "        img = img.to(device=device, dtype=torch.float32)\n",
    "        mask = mask.to(device=device, dtype=torch.float32)\n",
    "        perc = perc.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        print(batch['image_ID'][i])\n",
    "        \n",
    "        gt_image = gt_torchToPIL_img(img)\n",
    "        gt_mask = gt_torchToPIL_mask(mask)\n",
    "        \n",
    "        img = torch.unsqueeze(img, 0)\n",
    "        \n",
    "        outs = net_ml(img)\n",
    "        _, ml_mask = outs['aux'], outs['out']\n",
    "#         seg_mask = net_seg(img)\n",
    "        \n",
    "#         print(ml_mask.shape, seg_mask.shape)\n",
    "        \n",
    "        ml_mask_disp = ml_torchToPIL_mask(ml_mask)\n",
    "#         seg_mask_disp = seg_torchToPIL_mask(seg_mask)\n",
    "        \n",
    "#         combined_image = combined_display_pic([gt_image, gt_mask, ml_mask_disp, seg_mask_disp])\n",
    "        combined_image = combined_display_pic([gt_image, gt_mask, ml_mask_disp])\n",
    "        display(combined_image)\n",
    "        \n",
    "        ml_mask = ml_mask[0]\n",
    "#         seg_mask = seg_mask[0]\n",
    "        ml_iou = single_iou(ml_mask, mask)\n",
    "#         seg_iou = single_iou(seg_mask, mask)\n",
    "        random_iou = random_pred_expected_iou(perc)\n",
    "        \n",
    "        batch_iou_ml += ml_iou\n",
    "#         batch_iou_seg += seg_iou\n",
    "        \n",
    "        print(\"Image Metrics: \", \"ML IoU: \", ml_iou, \"Random Pred IoU: \", random_iou)\n",
    "    batch_iou_ml = batch_iou_ml / batch_size\n",
    "#     batch_iou_seg = batch_iou_seg / batch_size\n",
    "    print(\"Batch Metrics: \", \"ML IoU: \", batch_iou_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389611ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2769ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
